{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####\n",
    "PART 2 - FORM INSTRUCTIONS: \n",
    "\n",
    "2.1. Make a regression model\n",
    "\n",
    "    The model should be selected from Linear Regression or Decision Tree regression (Use scikit learn implementations!)\n",
    "    Create two models:\n",
    "        1) with the full dataset (direct variables)\n",
    "        2) with a projection of the full data in a smaller feature space\n",
    "    Discuss your results\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Linear regression of the full dataset '''\n",
    "\n",
    "#### STill working on this one. Not sure what I am doing.... ######\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# associate data with the variables here\n",
    "X = Superconduct_X ##### Replace here with full clean data\n",
    "y = Superconduct_y ##### Replace here with full clean data\n",
    "\n",
    "# Create and fit a linear regression model\n",
    "model = linear_model.LinearRegression() # Create linear regression object\n",
    "model.fit(Superconduct_X, Superconduct_y) # Train the model using the training sets\n",
    "\n",
    "# Make predictions using the testing set\n",
    "Superconduct_y_pred = model.predict(Superconduct_X_test) ##### Replace here with test\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Coefficients:\", model.coef_) # print the coefficients\n",
    "print(\"Intercept:\", model.intercept_) # print the intercept\n",
    "print(\"Mean squared error:\", mean_squared_error(y, model.predict(X))) # print the MSE on training data\n",
    "print(\"R2 score:\", r2_score(y, model.predict(X))) # print the R2 score on training data\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(Superconduct_X_test, Superconduct_y_test, color=\"black\")\n",
    "plt.plot(Superconduct_X_test, Superconduct_y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LINEAR MODEL OF THE PCA \n",
    "\n",
    "By using a PCA, we can select a subset of principal components that capture most of the variation in the data, and use them as predictors in the regression model. This can help us avoid overfitting, multicollinearity, and noise issues that may arise from using too many or irrelevant features. Below is the linear regression of the projected data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Linear regression of the PCA projection '''\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# associate data with the variables here\n",
    "X = Superconduct_X_train ##### Replace here with train\n",
    "y = Superconduct_y_train ##### Replace here with train\n",
    "\n",
    "# Create and fit a linear regression model\n",
    "model = linear_model.LinearRegression() # Create linear regression object\n",
    "model.fit(Superconduct_X_train, Superconduct_y_train) # Train the model using the training sets\n",
    "\n",
    "# Make predictions using the testing set\n",
    "Superconduct_y_pred = model.predict(Superconduct_X_test) ##### Replace here with test\n",
    "\n",
    "# Evaluate the model performance\n",
    "print(\"Coefficients:\", model.coef_) # print the coefficients\n",
    "print(\"Intercept:\", model.intercept_) # print the intercept\n",
    "print(\"Mean squared error:\", mean_squared_error(y, model.predict(X))) # print the MSE on training data\n",
    "print(\"R2 score:\", r2_score(y, model.predict(X))) # print the R2 score on training data\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(Superconduct_X_test, Superconduct_y_test, color=\"black\")\n",
    "plt.plot(Superconduct_X_test, Superconduct_y_pred, color=\"blue\", linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Regression\n",
    "\n",
    "Decision tree regression is a method of fitting a piecewise constant function to the data by learning simple decision rules inferred from the features. A decision tree is a tree-like structure that splits the data into subsets based on the values of the features. Each node in the tree represents a feature, each branch represents a decision rule, and each leaf represents an output value. The output value of a decision tree regression is the average of the target values in the leaf node2. Decision tree regression can handle both numerical and categorical features, and can capture complex nonlinear relationships in the data3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Decision Tree Regression '''\n",
    "\n",
    "#### AGAIN: STill working on this one. Not sure what I am doing.... Not even sure we need the decision tree regression ######\n",
    "\n",
    "\n",
    "# Import the necessary modules and libraries\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import dataset\n",
    "\n",
    "\n",
    "# Fit regression model\n",
    "regr_1 = DecisionTreeRegressor(max_depth=2 ) ### dont know what depth means\n",
    "regr_2 = DecisionTreeRegressor(max_depth=5) ### dont know what deapth means\n",
    "regr_1.fit(X, y)\n",
    "regr_2.fit(X, y)\n",
    "\n",
    "# Predict\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "y_1 = regr_1.predict(X_test)\n",
    "y_2 = regr_2.predict(X_test)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure()\n",
    "plt.scatter(X, y, s=20, edgecolor=\"black\", c=\"darkorange\", label=\"data\")\n",
    "plt.plot(X_test, y_1, color=\"cornflowerblue\", label=\"max_depth=2\", linewidth=2)\n",
    "plt.plot(X_test, y_2, color=\"yellowgreen\", label=\"max_depth=5\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"Decision Tree Regression\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DISCUSSION OF PART 2.1:\n",
    "\n",
    "bla bla, I wish I knew"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
